{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA part of the same notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Here you need to have same Python version on your local machine and on worker node i.e. EC2. here both should have python3.\n",
    "#os.environ[\"PYSPARK_PYTHON\"] = \"/bin/python3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Credit').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = spark.read.csv(\"application_record.csv\", header=True, inferSchema=True)\n",
    "#df_application = pd.read_csv(\"application_record.csv\")\n",
    "#df_application.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- CODE_GENDER: string (nullable = true)\n",
      " |-- FLAG_OWN_CAR: string (nullable = true)\n",
      " |-- FLAG_OWN_REALTY: string (nullable = true)\n",
      " |-- CNT_CHILDREN: integer (nullable = true)\n",
      " |-- AMT_INCOME_TOTAL: double (nullable = true)\n",
      " |-- NAME_INCOME_TYPE: string (nullable = true)\n",
      " |-- NAME_EDUCATION_TYPE: string (nullable = true)\n",
      " |-- NAME_FAMILY_STATUS: string (nullable = true)\n",
      " |-- NAME_HOUSING_TYPE: string (nullable = true)\n",
      " |-- DAYS_BIRTH: integer (nullable = true)\n",
      " |-- DAYS_EMPLOYED: integer (nullable = true)\n",
      " |-- FLAG_MOBIL: integer (nullable = true)\n",
      " |-- FLAG_WORK_PHONE: integer (nullable = true)\n",
      " |-- FLAG_PHONE: integer (nullable = true)\n",
      " |-- FLAG_EMAIL: integer (nullable = true)\n",
      " |-- OCCUPATION_TYPE: string (nullable = true)\n",
      " |-- CNT_FAM_MEMBERS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking which columns have a lot of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134203"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application.where(F.col(\"OCCUPATION_TYPE\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does OCCUPATION_TYPE have so many null entrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|     OCCUPATION_TYPE| count|\n",
      "+--------------------+------+\n",
      "|                null|134203|\n",
      "|            Managers| 35487|\n",
      "|            HR staff|   774|\n",
      "|      Medicine staff| 13520|\n",
      "|         Accountants| 15985|\n",
      "|            Laborers| 78240|\n",
      "|      Cleaning staff|  5845|\n",
      "|Private service s...|  3456|\n",
      "|             Drivers| 26090|\n",
      "|         Sales staff| 41098|\n",
      "|       Realty agents|  1041|\n",
      "|            IT staff|   604|\n",
      "|      Security staff|  7993|\n",
      "|         Secretaries|  2044|\n",
      "|  Low-skill Laborers|  2140|\n",
      "|          Core staff| 43007|\n",
      "|       Cooking staff|  8076|\n",
      "|High skill tech s...| 17289|\n",
      "|Waiters/barmen staff|  1665|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.groupby('OCCUPATION_TYPE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Could be because a majority of them are retired and pension money is their only income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replacement to value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_application.groupBy('OCCUPATION_TYPE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|    NAME_INCOME_TYPE|count|\n",
      "+--------------------+-----+\n",
      "|           Pensioner|75357|\n",
      "|             Working|35886|\n",
      "|Commercial associate|16745|\n",
      "|       State servant| 6210|\n",
      "|             Student|    5|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.where(F.col(\"OCCUPATION_TYPE\").isNull()).select(\"NAME_INCOME_TYPE\")\\\n",
    ".groupBy('NAME_INCOME_TYPE')\\\n",
    ".count()\\\n",
    ".orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling all null entries in OCCUPATION_TYPE with \"Not working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_application = df_application.fillna({'OCCUPATION_TYPE':'Not working'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------------+---------------+------------+----------------+----------------+-------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|ID |CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|NAME_INCOME_TYPE|NAME_EDUCATION_TYPE|NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+---+-----------+------------+---------------+------------+----------------+----------------+-------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|0  |0          |0           |0              |0           |0               |0               |0                  |0                 |0                |0         |0            |0         |0              |0         |0         |0              |0              |\n",
      "+---+-----------+------------+---------------+------------+----------------+----------------+-------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of null values in df_application\n",
    "df_application.select([count(when(col(c).isNull(), c)).alias(c) for c in df_application.columns]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking outleir in number of children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438549 18\n"
     ]
    }
   ],
   "source": [
    "df_application = df_application.where(\"CNT_CHILDREN !> 10\")\n",
    "print(df_application.count(), len(df_application.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_application.drop(df_application[df_application['CNT_CHILDREN']>10].index, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers in DAYS_BIRTH / DAYS_EMPLOYEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application.where('DAYS_BIRTH > 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_application[df_application['DAYS_BIRTH']>0]\n",
    "\n",
    "df_application[df_application['DAYS_EMPLOYED']>0]['NAME_INCOME_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Gender Demographic of the applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|CODE_GENDER| count|\n",
      "+-----------+------+\n",
      "|          M|144114|\n",
      "|          F|294435|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.groupBy('CODE_GENDER').count().orderBy('count').show()\n",
    "#df_application.groupBy('OCCUPATION_TYPE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 67% of the applicants are females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. House ownership among applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+------+\n",
      "|CODE_GENDER|FLAG_OWN_REALTY| count|\n",
      "+-----------+---------------+------+\n",
      "|          F|              N| 86302|\n",
      "|          F|              Y|208133|\n",
      "|          M|              Y| 95933|\n",
      "|          M|              N| 48181|\n",
      "+-----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.select('FLAG_OWN_REALTY', 'CODE_GENDER').groupBy('CODE_GENDER', 'FLAG_OWN_REALTY').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### House ownership is higher among females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Correlation between income level and education level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping the various levels of education to a number, to convert it to an integer type, then performing corr() on the dataframe,\n",
    "##### reveals that there is a positive correlation betwen education level and income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|NAME_EDUCATION_TYPE          |\n",
      "+-----------------------------+\n",
      "|Academic degree              |\n",
      "|Incomplete higher            |\n",
      "|Secondary / secondary special|\n",
      "|Lower secondary              |\n",
      "|Higher education             |\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.select(\"NAME_EDUCATION_TYPE\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {'Academic degree':5, \\\n",
    "                 'Incomplete higher':3, \\\n",
    "                 'Secondary / secondary special':2, \\\n",
    "                 'Lower secondary':1, \\\n",
    "                 'Higher education':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = udf(lambda x: education_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = df_application.withColumn('EDUCATION_MAP', mapper(df_application['NAME_EDUCATION_TYPE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- CODE_GENDER: string (nullable = true)\n",
      " |-- FLAG_OWN_CAR: string (nullable = true)\n",
      " |-- FLAG_OWN_REALTY: string (nullable = true)\n",
      " |-- CNT_CHILDREN: integer (nullable = true)\n",
      " |-- AMT_INCOME_TOTAL: double (nullable = true)\n",
      " |-- NAME_INCOME_TYPE: string (nullable = true)\n",
      " |-- NAME_EDUCATION_TYPE: string (nullable = true)\n",
      " |-- NAME_FAMILY_STATUS: string (nullable = true)\n",
      " |-- NAME_HOUSING_TYPE: string (nullable = true)\n",
      " |-- DAYS_BIRTH: integer (nullable = true)\n",
      " |-- DAYS_EMPLOYED: integer (nullable = true)\n",
      " |-- FLAG_MOBIL: integer (nullable = true)\n",
      " |-- FLAG_WORK_PHONE: integer (nullable = true)\n",
      " |-- FLAG_PHONE: integer (nullable = true)\n",
      " |-- FLAG_EMAIL: integer (nullable = true)\n",
      " |-- OCCUPATION_TYPE: string (nullable = false)\n",
      " |-- CNT_FAM_MEMBERS: double (nullable = true)\n",
      " |-- EDUCATION_MAP: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change datatype of EDUCATION_MAP from string to Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "df_application = df_application.withColumn(\"EDUCATION_MAP\", df_application['EDUCATION_MAP'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change Datatype of CNT_FAM_MEMBERS from double to Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = df_application.withColumn(\"CNT_FAM_MEMBERS\", df_application['CNT_FAM_MEMBERS'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = df_application.drop(\"NAME_EDUCATION_TYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Datatype of INCOME to Integer type\n",
    "df_application = df_application.withColumn(\"AMT_INCOME_TOTAL\", df_application['AMT_INCOME_TOTAL'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- CODE_GENDER: string (nullable = true)\n",
      " |-- FLAG_OWN_CAR: string (nullable = true)\n",
      " |-- FLAG_OWN_REALTY: string (nullable = true)\n",
      " |-- CNT_CHILDREN: integer (nullable = true)\n",
      " |-- AMT_INCOME_TOTAL: integer (nullable = true)\n",
      " |-- NAME_INCOME_TYPE: string (nullable = true)\n",
      " |-- NAME_FAMILY_STATUS: string (nullable = true)\n",
      " |-- NAME_HOUSING_TYPE: string (nullable = true)\n",
      " |-- DAYS_BIRTH: integer (nullable = true)\n",
      " |-- DAYS_EMPLOYED: integer (nullable = true)\n",
      " |-- FLAG_MOBIL: integer (nullable = true)\n",
      " |-- FLAG_WORK_PHONE: integer (nullable = true)\n",
      " |-- FLAG_PHONE: integer (nullable = true)\n",
      " |-- FLAG_EMAIL: integer (nullable = true)\n",
      " |-- OCCUPATION_TYPE: string (nullable = false)\n",
      " |-- CNT_FAM_MEMBERS: integer (nullable = true)\n",
      " |-- EDUCATION_MAP: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', \\\n",
    "        'DAYS_BIRTH', 'DAYS_EMPLOYED', \\\n",
    "        'FLAG_MOBIL', 'FLAG_WORK_PHONE', \\\n",
    "        'FLAG_PHONE', 'FLAG_EMAIL', \\\n",
    "        'CNT_FAM_MEMBERS', 'EDUCATION_MAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df, corr_columns, method='pearson'):\n",
    "    vector_col = \"corr_features\"\n",
    "    assembler = VectorAssembler(inputCols=corr_columns, outputCol=vector_col)\n",
    "    df_vector = assembler.transform(df).select(vector_col)\n",
    "    matrix = Correlation.corr(df_vector, vector_col, method)\n",
    "\n",
    "    result = matrix.collect()[0][\"pearson({})\".format(vector_col)].values\n",
    "    return pd.DataFrame(result.reshape(-1, len(corr_columns)), columns=corr_columns, index=corr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>EDUCATION_MAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>-0.242140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>-0.038304</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.038042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>0.019034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>-0.141287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033625</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.112145</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.221414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.617909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171826</td>\n",
       "      <td>-0.037987</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>0.306707</td>\n",
       "      <td>0.154552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <td>-0.242140</td>\n",
       "      <td>-0.141287</td>\n",
       "      <td>-0.617909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.232212</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>-0.074375</td>\n",
       "      <td>-0.234709</td>\n",
       "      <td>-0.120346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <td>0.038563</td>\n",
       "      <td>-0.033625</td>\n",
       "      <td>0.171826</td>\n",
       "      <td>-0.232212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290058</td>\n",
       "      <td>-0.060916</td>\n",
       "      <td>0.049897</td>\n",
       "      <td>0.016055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <td>-0.038304</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>-0.037987</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.024193</td>\n",
       "      <td>0.036007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.112145</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>-0.074375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.060916</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>0.102167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.306707</td>\n",
       "      <td>-0.234709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049897</td>\n",
       "      <td>-0.024193</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_MAP</th>\n",
       "      <td>0.038042</td>\n",
       "      <td>0.221414</td>\n",
       "      <td>0.154552</td>\n",
       "      <td>-0.120346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>0.102167</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT_CHILDREN  AMT_INCOME_TOTAL  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "CNT_CHILDREN          1.000000          0.019034    0.350098      -0.242140   \n",
       "AMT_INCOME_TOTAL      0.019034          1.000000    0.053772      -0.141287   \n",
       "DAYS_BIRTH            0.350098          0.053772    1.000000      -0.617909   \n",
       "DAYS_EMPLOYED        -0.242140         -0.141287   -0.617909       1.000000   \n",
       "FLAG_MOBIL                 NaN               NaN         NaN            NaN   \n",
       "FLAG_WORK_PHONE       0.038563         -0.033625    0.171826      -0.232212   \n",
       "FLAG_PHONE           -0.038304          0.004456   -0.037987       0.004865   \n",
       "FLAG_EMAIL            0.028662          0.112145    0.096754      -0.074375   \n",
       "CNT_FAM_MEMBERS       0.884340          0.011310    0.306707      -0.234709   \n",
       "EDUCATION_MAP         0.038042          0.221414    0.154552      -0.120346   \n",
       "\n",
       "                  FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL  \\\n",
       "CNT_CHILDREN             NaN         0.038563   -0.038304    0.028662   \n",
       "AMT_INCOME_TOTAL         NaN        -0.033625    0.004456    0.112145   \n",
       "DAYS_BIRTH               NaN         0.171826   -0.037987    0.096754   \n",
       "DAYS_EMPLOYED            NaN        -0.232212    0.004865   -0.074375   \n",
       "FLAG_MOBIL               1.0              NaN         NaN         NaN   \n",
       "FLAG_WORK_PHONE          NaN         1.000000    0.290058   -0.060916   \n",
       "FLAG_PHONE               NaN         0.290058    1.000000   -0.001173   \n",
       "FLAG_EMAIL               NaN        -0.060916   -0.001173    1.000000   \n",
       "CNT_FAM_MEMBERS          NaN         0.049897   -0.024193    0.022189   \n",
       "EDUCATION_MAP            NaN         0.016055    0.036007    0.102167   \n",
       "\n",
       "                  CNT_FAM_MEMBERS  EDUCATION_MAP  \n",
       "CNT_CHILDREN             0.884340       0.038042  \n",
       "AMT_INCOME_TOTAL         0.011310       0.221414  \n",
       "DAYS_BIRTH               0.306707       0.154552  \n",
       "DAYS_EMPLOYED           -0.234709      -0.120346  \n",
       "FLAG_MOBIL                    NaN            NaN  \n",
       "FLAG_WORK_PHONE          0.049897       0.016055  \n",
       "FLAG_PHONE              -0.024193       0.036007  \n",
       "FLAG_EMAIL               0.022189       0.102167  \n",
       "CNT_FAM_MEMBERS          1.000000       0.025808  \n",
       "EDUCATION_MAP            0.025808       1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix(df_application, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There is a correlation between education level and income, higher the education, higher the income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Average and median salary of the applicant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean = 187522.832 ; median = 162000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean as _mean, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|avg(AMT_INCOME_TOTAL)|\n",
      "+---------------------+\n",
      "|    187522.8322285537|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_application.select(_mean(col('AMT_INCOME_TOTAL'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median of AMT_INCOME_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[162000.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application.approxQuantile('AMT_INCOME_TOTAL', [0.5], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing credit dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_credit = spark.read.csv('credit_record.csv', header =True, inferSchema=True)\n",
    "#df_credit.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map = {'5':-6, '4':-5, '3':-4, '2':-3, '1':-2, '0':-1, 'C':0, 'X':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the STATUSes to a predefined index, since it is an ordinal variable\n",
    "mapper = udf(lambda x: status_map[x])\n",
    "\n",
    "df_credit = df_credit.withColumn('STATUS_INDEX', mapper(df_credit['STATUS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datatype of that STATUS_INDEX is string, SO convert it to Integer type\n",
    "df_credit = df_credit.withColumn(\"STATUS_INDEX\", df_credit['STATUS_INDEX'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant column\n",
    "df_credit = df_credit.drop(\"STATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all Distinct Customers into a list\n",
    "customer_ids = df_credit.select('ID').distinct().collect()\n",
    "\n",
    "customer_ids = [int(row.ID) for row in customer_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45985"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique customers\n",
    "len(customer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all late payments. \n",
    "# All payments taking more than 30 days (-1) can be considered as late payment\n",
    "late_payment_df = df_credit.select('ID', 'STATUS_INDEX').where(\"STATUS_INDEX <= -1\").groupby('ID').count()\n",
    "late_payment_df = late_payment_df.select(*(col(x).alias(x + '_df1') for x in late_payment_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with Total number of payments made by each customer\n",
    "total_payment_df = df_credit.groupby('ID').count()\n",
    "total_payment_df = total_payment_df.select(*(col(x).alias(x + '_df2') for x in total_payment_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a temporary dataframe to work with the late payments to get all the customer who can be termed as LATE\n",
    "temp = late_payment_df.join(total_payment_df, late_payment_df.ID_df1 == total_payment_df.ID_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of late/total_payments_made\n",
    "temp = temp.withColumn(\"late_proportion\", (F.col(\"count_df1\")/F.col(\"count_df2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UDF to term all the customer whose (late/total_payments_made > 0.98) as late\n",
    "mapper = udf(lambda x: 1 if x>0.98 else 0)\n",
    "temp = temp.withColumn('LATE', mapper(temp['late_proportion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.groupBy('LATE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting collect() to list()\n",
    "late_customers = temp.select(col(\"ID_df1\").alias('ID')).where(\"LATE == 1\").collect()\n",
    "\n",
    "late_customers = [int(row.ID) for row in late_customers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping all the late_customer to the original df_credits dataframe\n",
    "mapper = udf(lambda x: 1 if x in late_customers else 0)\n",
    "df_credit = df_credit.withColumn('LATE', mapper(df_credit['ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### value_counts() how many LATE and how many Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_credit.groupBy(\"LATE\").count().orderBy('count').show()\n",
    "#temp.groupBy('LATE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant column\n",
    "df_credit = df_credit.drop(\"MONTHS_BALANCE\", \"STATUS_INDEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows. What remains is all the customer_ids who were marked as late or not\n",
    "df_credit = df_credit.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = df_credit.select(col(\"ID\").alias('ID_credit'), col(\"LATE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|ID_credit|LATE|\n",
      "+---------+----+\n",
      "|  5001796|   0|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_credit.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join Application and Credit history dataframes on customer ids\n",
    "df = df_credit.join(df_application, df_credit.ID_credit==df_application.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ID\", \"ID_credit\", \"FLAG_MOBIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consider LATE is the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Is the proportion of bad customers higher for people who own cars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To get percentages of the occurances in a column with groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+-----+----------+\n",
      "|FLAG_OWN_CAR|LATE|count|percentage|\n",
      "+------------+----+-----+----------+\n",
      "|           Y|   1| 1852|     0.051|\n",
      "|           N|   0|19393|     0.532|\n",
      "|           Y|   0|11988|     0.329|\n",
      "|           N|   1| 3220|     0.088|\n",
      "+------------+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(['FLAG_OWN_CAR', 'LATE']).count().withColumn('percentage', \\\n",
    "                                                        F.round(F.col('count') / F.sum('count')\\\n",
    "                                                                .over(Window.partitionBy()),3)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No, of the people that own cars only 0.017 are bad customers whereas the proportion of bad customers who dont own a car is 0.036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Do people living on rent have a higher proportion of bad customers compared to the rest of the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thats not the case, the proportion of bad customers who live in rented house is not the highest of all other types of housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+----------+\n",
      "|  NAME_HOUSING_TYPE|LATE|count|percentage|\n",
      "+-------------------+----+-----+----------+\n",
      "|   Rented apartment|   1|   80|     0.002|\n",
      "|    Co-op apartment|   0|  153|     0.004|\n",
      "|Municipal apartment|   1|  147|     0.004|\n",
      "|       With parents|   0| 1523|     0.042|\n",
      "|    Co-op apartment|   1|   15|       0.0|\n",
      "|   Rented apartment|   0|  495|     0.014|\n",
      "|   Office apartment|   1|   45|     0.001|\n",
      "|   Office apartment|   0|  217|     0.006|\n",
      "|Municipal apartment|   0|  981|     0.027|\n",
      "|  House / apartment|   0|28012|     0.768|\n",
      "|       With parents|   1|  253|     0.007|\n",
      "|  House / apartment|   1| 4532|     0.124|\n",
      "+-------------------+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"NAME_HOUSING_TYPE\", \"LATE\").count()\\\n",
    ".withColumn('percentage', \\\n",
    "            F.round(F.col('count') / F.sum('count')\\\n",
    "                    .over(Window.partitionBy()), 3)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Do single customers have a high proportion of bad customers compared to married customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+----------+\n",
      "|  NAME_FAMILY_STATUS|LATE|count|percentage|\n",
      "+--------------------+----+-----+----------+\n",
      "|           Separated|   1|  244|     0.007|\n",
      "|               Widow|   0| 1317|     0.036|\n",
      "|             Married|   0|21553|     0.591|\n",
      "|      Civil marriage|   0| 2562|      0.07|\n",
      "|Single / not married|   0| 4093|     0.112|\n",
      "|      Civil marriage|   1|  383|     0.011|\n",
      "|             Married|   1| 3495|     0.096|\n",
      "|           Separated|   0| 1856|     0.051|\n",
      "|               Widow|   1|  215|     0.006|\n",
      "|Single / not married|   1|  735|      0.02|\n",
      "+--------------------+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"NAME_FAMILY_STATUS\", 'LATE')\\\n",
    ".count().withColumn('percentage', \\\n",
    "                    F.round(F.col('count') / F.sum('count')\\\n",
    "                            .over(Window.partitionBy()),3)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NO, the proportion of bad customers who are single is 0.008 , \n",
    "##### Proportion of bad customers who are married is 0.033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credit status of Pensioners.\n",
    "#### Majority of the Pensioners are not LATE on their payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|LATE|count|\n",
      "+----+-----+\n",
      "|   1|  860|\n",
      "|   0| 5292|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"LATE\").where(\"NAME_INCOME_TYPE == 'Pensioner'\").groupBy('LATE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOE and IV value calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First convert all the float values to int type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"LATE\", df['LATE'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using spearman correlation for monotomic binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "max_bin = 20\n",
    "force_bin = 3\n",
    "\n",
    "# define a binning function\n",
    "def mono_bin(Y, X, n = max_bin):\n",
    "    \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]\n",
    "    r = 0\n",
    "    while np.abs(r) < 1:\n",
    "        try:\n",
    "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
    "            d2 = d1.groupby('Bucket', as_index=True)\n",
    "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "            n = n - 1 \n",
    "        except Exception as e:\n",
    "            n = n - 1\n",
    "\n",
    "    if len(d2) == 1:\n",
    "        n = force_bin         \n",
    "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
    "        if len(np.unique(bins)) == 2:\n",
    "            bins = np.insert(bins, 0, 1)\n",
    "            bins[1] = bins[1]-(bins[1]/2)\n",
    "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
    "        d2 = d1.groupby('Bucket', as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"MIN_VALUE\"] = d2.min().X\n",
    "    d3[\"MAX_VALUE\"] = d2.max().X\n",
    "    d3[\"COUNT\"] = d2.count().Y\n",
    "    d3[\"EVENT\"] = d2.sum().Y\n",
    "    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
    "    d3=d3.reset_index(drop=True)\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def char_bin(Y, X):\n",
    "        \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
    "    df2 = notmiss.groupby('X',as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"COUNT\"] = df2.count().Y\n",
    "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
    "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
    "    d3[\"EVENT\"] = df2.sum().Y\n",
    "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    d3 = d3.reset_index(drop=True)\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def data_vars(df1, target):\n",
    "    \n",
    "    stack = traceback.extract_stack()\n",
    "    filename, lineno, function_name, code = stack[-2]\n",
    "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
    "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
    "    \n",
    "    x = df1.dtypes.index\n",
    "    count = -1\n",
    "    \n",
    "    for i in x:\n",
    "        if i.upper() not in (final.upper()):\n",
    "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
    "                conv = mono_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i\n",
    "                count = count + 1\n",
    "            else:\n",
    "                conv = char_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i            \n",
    "                count = count + 1\n",
    "                \n",
    "            if count == 0:\n",
    "                iv_df = conv\n",
    "            else:\n",
    "                iv_df = iv_df.append(conv,ignore_index=True)\n",
    "    \n",
    "    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
    "    iv = iv.reset_index()\n",
    "    return(iv_df,iv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.6/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "final_iv, IV = data_vars(df_pandas,df_pandas.LATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_NAME</th>\n",
       "      <th>MIN_VALUE</th>\n",
       "      <th>MAX_VALUE</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>EVENT_RATE</th>\n",
       "      <th>NONEVENT</th>\n",
       "      <th>NON_EVENT_RATE</th>\n",
       "      <th>DIST_EVENT</th>\n",
       "      <th>DIST_NON_EVENT</th>\n",
       "      <th>WOE</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>24429</td>\n",
       "      <td>3397.0</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>21032.0</td>\n",
       "      <td>0.860944</td>\n",
       "      <td>0.669756</td>\n",
       "      <td>0.670214</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>9.526075e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>12024</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>0.139305</td>\n",
       "      <td>10349.0</td>\n",
       "      <td>0.860695</td>\n",
       "      <td>0.330244</td>\n",
       "      <td>0.329786</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>9.526075e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>22613</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.142396</td>\n",
       "      <td>19393.0</td>\n",
       "      <td>0.857604</td>\n",
       "      <td>0.634858</td>\n",
       "      <td>0.617985</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>1.216672e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>13840</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>0.133815</td>\n",
       "      <td>11988.0</td>\n",
       "      <td>0.866185</td>\n",
       "      <td>0.365142</td>\n",
       "      <td>0.382015</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>1.216672e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>11951</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>0.136139</td>\n",
       "      <td>10324.0</td>\n",
       "      <td>0.863861</td>\n",
       "      <td>0.320781</td>\n",
       "      <td>0.328989</td>\n",
       "      <td>-0.025266</td>\n",
       "      <td>3.071833e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VAR_NAME MIN_VALUE MAX_VALUE  COUNT   EVENT  EVENT_RATE  NONEVENT  \\\n",
       "0      CODE_GENDER         F         F  24429  3397.0    0.139056   21032.0   \n",
       "1      CODE_GENDER         M         M  12024  1675.0    0.139305   10349.0   \n",
       "2     FLAG_OWN_CAR         N         N  22613  3220.0    0.142396   19393.0   \n",
       "3     FLAG_OWN_CAR         Y         Y  13840  1852.0    0.133815   11988.0   \n",
       "4  FLAG_OWN_REALTY         N         N  11951  1627.0    0.136139   10324.0   \n",
       "\n",
       "   NON_EVENT_RATE  DIST_EVENT  DIST_NON_EVENT       WOE            IV  \n",
       "0        0.860944    0.669756        0.670214 -0.000685  9.526075e-07  \n",
       "1        0.860695    0.330244        0.329786  0.001391  9.526075e-07  \n",
       "2        0.857604    0.634858        0.617985  0.026937  1.216672e-03  \n",
       "3        0.866185    0.365142        0.382015 -0.045173  1.216672e-03  \n",
       "4        0.863861    0.320781        0.328989 -0.025266  3.071833e-04  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_iv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_NAME</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>2.041860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNT_CHILDREN</td>\n",
       "      <td>4.946421e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNT_FAM_MEMBERS</td>\n",
       "      <td>4.438522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>9.526075e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>1.132718e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>4.936329e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDUCATION_MAP</td>\n",
       "      <td>3.542516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FLAG_EMAIL</td>\n",
       "      <td>5.597212e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>1.216672e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "      <td>3.071833e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FLAG_PHONE</td>\n",
       "      <td>4.128654e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FLAG_WORK_PHONE</td>\n",
       "      <td>1.671099e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NAME_FAMILY_STATUS</td>\n",
       "      <td>4.294774e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NAME_HOUSING_TYPE</td>\n",
       "      <td>1.657013e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NAME_INCOME_TYPE</td>\n",
       "      <td>2.818875e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OCCUPATION_TYPE</td>\n",
       "      <td>6.914781e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR_NAME            IV\n",
       "0     AMT_INCOME_TOTAL  2.041860e-03\n",
       "1         CNT_CHILDREN  4.946421e-04\n",
       "2      CNT_FAM_MEMBERS  4.438522e-04\n",
       "3          CODE_GENDER  9.526075e-07\n",
       "4           DAYS_BIRTH  1.132718e-04\n",
       "5        DAYS_EMPLOYED  4.936329e-03\n",
       "6        EDUCATION_MAP  3.542516e-03\n",
       "7           FLAG_EMAIL  5.597212e-04\n",
       "8         FLAG_OWN_CAR  1.216672e-03\n",
       "9      FLAG_OWN_REALTY  3.071833e-04\n",
       "10          FLAG_PHONE  4.128654e-04\n",
       "11     FLAG_WORK_PHONE  1.671099e-03\n",
       "12  NAME_FAMILY_STATUS  4.294774e-03\n",
       "13   NAME_HOUSING_TYPE  1.657013e-03\n",
       "14    NAME_INCOME_TYPE  2.818875e-04\n",
       "15     OCCUPATION_TYPE  6.914781e-03"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply WOE values to the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_vars_list = df_pandas.columns.difference(['LATE'])\n",
    "transform_prefix = 'new_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'CODE_GENDER',\n",
       "       'DAYS_BIRTH', 'DAYS_EMPLOYED', 'EDUCATION_MAP', 'FLAG_EMAIL',\n",
       "       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_PHONE', 'FLAG_WORK_PHONE',\n",
       "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'NAME_INCOME_TYPE',\n",
       "       'OCCUPATION_TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in transform_vars_list:\n",
    "    small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
    "    transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
    "    replace_cmd = ''\n",
    "    replace_cmd1 = ''\n",
    "    for i in sorted(transform_dict.items()):\n",
    "        replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
    "        replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
    "    replace_cmd = replace_cmd + '0'\n",
    "    replace_cmd1 = replace_cmd1 + '0'\n",
    "    if replace_cmd != '0':\n",
    "        try:\n",
    "            df_pandas[transform_prefix + var] = df_pandas[var].apply(lambda x: eval(replace_cmd))\n",
    "        except:\n",
    "            df_pandas[transform_prefix + var] = df_pandas[var].apply(lambda x: eval(replace_cmd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.drop(transform_vars_list, axis = 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn(\"LATE\", df_spark['LATE'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LATE: integer (nullable = true)\n",
      " |-- new_AMT_INCOME_TOTAL: double (nullable = true)\n",
      " |-- new_CNT_CHILDREN: double (nullable = true)\n",
      " |-- new_CNT_FAM_MEMBERS: double (nullable = true)\n",
      " |-- new_CODE_GENDER: double (nullable = true)\n",
      " |-- new_DAYS_BIRTH: double (nullable = true)\n",
      " |-- new_DAYS_EMPLOYED: double (nullable = true)\n",
      " |-- new_EDUCATION_MAP: double (nullable = true)\n",
      " |-- new_FLAG_EMAIL: double (nullable = true)\n",
      " |-- new_FLAG_OWN_CAR: double (nullable = true)\n",
      " |-- new_FLAG_OWN_REALTY: double (nullable = true)\n",
      " |-- new_FLAG_PHONE: double (nullable = true)\n",
      " |-- new_FLAG_WORK_PHONE: double (nullable = true)\n",
      " |-- new_NAME_FAMILY_STATUS: double (nullable = true)\n",
      " |-- new_NAME_HOUSING_TYPE: double (nullable = true)\n",
      " |-- new_NAME_INCOME_TYPE: double (nullable = true)\n",
      " |-- new_OCCUPATION_TYPE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have the dataframe with WOE values for all the features, we can build a model for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, Its better to write this final dataframe to csv file for faster access in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_spark.coalesce(1).write.option(\"header\", \"true\").parquet(\"./DATAFRAME_CHECKPOINTS/df_new.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_spark.coalesce(1).write.csv('WOE_CSV_new.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.parquet('./DATAFRAME_CHECKPOINTS/df_new.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36453"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|LATE|count|\n",
      "+----+-----+\n",
      "|   1| 5072|\n",
      "|   0|31381|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('LATE').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCols = df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to use in training the model, removing the target variable\n",
    "trainCols.remove('LATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the assembler object and use it to transform df_spark\n",
    "assembler = VectorAssembler(inputCols = trainCols, outputCol='features')\n",
    "df_assembler = assembler.transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_assembler.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='LATE')\n",
    "model = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = model.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since this is vert close to 0.5, it can be interpretted that this model has very less class separation power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5395763064231398"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[LATE: int, new_AMT_INCOME_TOTAL: double, new_CNT_CHILDREN: double, new_CNT_FAM_MEMBERS: double, new_CODE_GENDER: double, new_DAYS_BIRTH: double, new_DAYS_EMPLOYED: double, new_EDUCATION_MAP: double, new_FLAG_EMAIL: double, new_FLAG_OWN_CAR: double, new_FLAG_OWN_REALTY: double, new_FLAG_PHONE: double, new_FLAG_WORK_PHONE: double, new_NAME_FAMILY_STATUS: double, new_NAME_HOUSING_TYPE: double, new_NAME_INCOME_TYPE: double, new_OCCUPATION_TYPE: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_test columns\n",
    "result_test.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = result_test.predictions.select('LATE', 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to access the probability of the positive class\n",
    "from pyspark.sql.functions import udf, when\n",
    "from pyspark.sql.types import FloatType\n",
    "element_extrac = udf(lambda v: float(v[1]), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all thresholds to check the metrics for\n",
    "result_list = []\n",
    "threshold_list = [0.1, 0.2, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add a task column, by comparing the probabilities with threshold\n",
    "for i in threshold_list:\n",
    "    test_pred = thresh.withColumn('label_p',when(element_extrac(thresh[\"probability\"]) >= i, 1).otherwise(0))\n",
    "    TP = test_pred.filter(\"LATE==1 AND label_p==1\").count()\n",
    "    FP = test_pred.filter(\"LATE==0 AND label_p==1\").count()\n",
    "    FN = test_pred.filter(\"LATE==1 AND label_p==0\").count()\n",
    "    TN = test_pred.filter(\"LATE==0 AND label_p==0\").count()    \n",
    "    recall = (TP/(TP+FN))\n",
    "    precision = ((TP/(TP+FP)))\n",
    "    list1 = []\n",
    "    list1.append(i)\n",
    "    list1.append(precision)\n",
    "    list1.append(recall)\n",
    "    list1.append(TP)\n",
    "    list1.append(TN)\n",
    "    list1.append(FP)\n",
    "    list1.append(FN)\n",
    "    result_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([StructField('threshold', FloatType(), True),\n",
    "                      StructField('precision', FloatType(), True),\n",
    "                      StructField('recall', FloatType(), True),\n",
    "                      StructField('TP', IntegerType(), True),\n",
    "                      StructField('TN', IntegerType(), True),\n",
    "                      StructField('FP', IntegerType(), True),\n",
    "                      StructField('FN', IntegerType(), True)])\n",
    "#create a rdd from the list\n",
    "rdd = spark.sparkContext.parallelize(result_list)\n",
    "\n",
    "\n",
    "# create a spark dataframe form rdd\n",
    "thresh_df = spark.createDataFrame(rdd,schema)\n",
    "\n",
    "# create pandas dataframe form the spark dataframe \n",
    "pandas_df = thresh_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplot` not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplot lib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create the plot\n",
    "pandas_df.plot.line(x='threshold', y=['precision','recall'])\n",
    "\n",
    "# display the plot\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number = thresh.count()\n",
    "positives = thresh.filter(\"LATE==1\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KS Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicted Probabilty dataframe from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_df = result_test.predictions.select('LATE','probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test_pred = probability_df.withColumn('label_p',element_extrac(probability_df[\"probability\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe to pandas\n",
    "pandas_prob_df = prob_test_pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks(data=None,target=None, prob=None):\n",
    "    data['target0'] = 1 - data[target]\n",
    "    data['bucket'] = pd.qcut(data[prob], 10)\n",
    "    grouped = data.groupby('bucket', as_index = False)\n",
    "    kstable = pd.DataFrame()\n",
    "    kstable['min_prob'] = grouped.min()[prob]\n",
    "    kstable['max_prob'] = grouped.max()[prob]\n",
    "    kstable['events']   = grouped.sum()[target]\n",
    "    kstable['nonevents'] = grouped.sum()['target0']\n",
    "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
    "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
    "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
    "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
    "\n",
    "    #Formating\n",
    "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
    "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
    "    kstable.index = range(1,11)\n",
    "    kstable.index.rename('Decile', inplace=True)\n",
    "    pd.set_option('display.max_columns', 9)\n",
    "    #print(kstable)\n",
    "    \n",
    "    #Display KS\n",
    "    #from colorama import Fore\n",
    "    #print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
    "    return(kstable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df = ks(data=pandas_prob_df,target=\"LATE\", prob=\"label_p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_prob</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>events</th>\n",
       "      <th>nonevents</th>\n",
       "      <th>event_rate</th>\n",
       "      <th>nonevent_rate</th>\n",
       "      <th>cum_eventrate</th>\n",
       "      <th>cum_noneventrate</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161237</td>\n",
       "      <td>0.261896</td>\n",
       "      <td>124</td>\n",
       "      <td>610</td>\n",
       "      <td>11.91%</td>\n",
       "      <td>9.70%</td>\n",
       "      <td>11.91%</td>\n",
       "      <td>9.70%</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151355</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>111</td>\n",
       "      <td>620</td>\n",
       "      <td>10.66%</td>\n",
       "      <td>9.86%</td>\n",
       "      <td>22.57%</td>\n",
       "      <td>19.55%</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.147785</td>\n",
       "      <td>0.151340</td>\n",
       "      <td>105</td>\n",
       "      <td>630</td>\n",
       "      <td>10.09%</td>\n",
       "      <td>10.01%</td>\n",
       "      <td>32.66%</td>\n",
       "      <td>29.57%</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143933</td>\n",
       "      <td>0.147761</td>\n",
       "      <td>120</td>\n",
       "      <td>603</td>\n",
       "      <td>11.53%</td>\n",
       "      <td>9.59%</td>\n",
       "      <td>44.19%</td>\n",
       "      <td>39.15%</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138927</td>\n",
       "      <td>0.143917</td>\n",
       "      <td>98</td>\n",
       "      <td>645</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>10.25%</td>\n",
       "      <td>53.60%</td>\n",
       "      <td>49.40%</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.138924</td>\n",
       "      <td>119</td>\n",
       "      <td>614</td>\n",
       "      <td>11.43%</td>\n",
       "      <td>9.76%</td>\n",
       "      <td>65.03%</td>\n",
       "      <td>59.16%</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129115</td>\n",
       "      <td>0.134105</td>\n",
       "      <td>104</td>\n",
       "      <td>629</td>\n",
       "      <td>9.99%</td>\n",
       "      <td>10.00%</td>\n",
       "      <td>75.02%</td>\n",
       "      <td>69.16%</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.123664</td>\n",
       "      <td>0.129105</td>\n",
       "      <td>87</td>\n",
       "      <td>646</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>10.27%</td>\n",
       "      <td>83.38%</td>\n",
       "      <td>79.43%</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.116012</td>\n",
       "      <td>0.123643</td>\n",
       "      <td>95</td>\n",
       "      <td>638</td>\n",
       "      <td>9.13%</td>\n",
       "      <td>10.14%</td>\n",
       "      <td>92.51%</td>\n",
       "      <td>89.57%</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>78</td>\n",
       "      <td>656</td>\n",
       "      <td>7.49%</td>\n",
       "      <td>10.43%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        min_prob  max_prob  events  nonevents event_rate nonevent_rate  \\\n",
       "Decile                                                                   \n",
       "1       0.161237  0.261896     124        610     11.91%         9.70%   \n",
       "2       0.151355  0.161200     111        620     10.66%         9.86%   \n",
       "3       0.147785  0.151340     105        630     10.09%        10.01%   \n",
       "4       0.143933  0.147761     120        603     11.53%         9.59%   \n",
       "5       0.138927  0.143917      98        645      9.41%        10.25%   \n",
       "6       0.134125  0.138924     119        614     11.43%         9.76%   \n",
       "7       0.129115  0.134105     104        629      9.99%        10.00%   \n",
       "8       0.123664  0.129105      87        646      8.36%        10.27%   \n",
       "9       0.116012  0.123643      95        638      9.13%        10.14%   \n",
       "10      0.067908  0.116000      78        656      7.49%        10.43%   \n",
       "\n",
       "       cum_eventrate cum_noneventrate   KS  \n",
       "Decile                                      \n",
       "1             11.91%            9.70%  2.2  \n",
       "2             22.57%           19.55%  3.0  \n",
       "3             32.66%           29.57%  3.1  \n",
       "4             44.19%           39.15%  5.0  \n",
       "5             53.60%           49.40%  4.2  \n",
       "6             65.03%           59.16%  5.9  \n",
       "7             75.02%           69.16%  5.9  \n",
       "8             83.38%           79.43%  4.0  \n",
       "9             92.51%           89.57%  2.9  \n",
       "10           100.00%          100.00%  0.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8999999999999995"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_df['KS'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_prob</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>events</th>\n",
       "      <th>nonevents</th>\n",
       "      <th>event_rate</th>\n",
       "      <th>nonevent_rate</th>\n",
       "      <th>cum_eventrate</th>\n",
       "      <th>cum_noneventrate</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.138924</td>\n",
       "      <td>119</td>\n",
       "      <td>614</td>\n",
       "      <td>11.43%</td>\n",
       "      <td>9.76%</td>\n",
       "      <td>65.03%</td>\n",
       "      <td>59.16%</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129115</td>\n",
       "      <td>0.134105</td>\n",
       "      <td>104</td>\n",
       "      <td>629</td>\n",
       "      <td>9.99%</td>\n",
       "      <td>10.00%</td>\n",
       "      <td>75.02%</td>\n",
       "      <td>69.16%</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        min_prob  max_prob  events  nonevents event_rate nonevent_rate  \\\n",
       "Decile                                                                   \n",
       "6       0.134125  0.138924     119        614     11.43%         9.76%   \n",
       "7       0.129115  0.134105     104        629      9.99%        10.00%   \n",
       "\n",
       "       cum_eventrate cum_noneventrate   KS  \n",
       "Decile                                      \n",
       "6             65.03%           59.16%  5.9  \n",
       "7             75.02%           69.16%  5.9  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_thresh = ks_df[ks_df['KS']==ks_df['KS'].max()]['min_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_thresh = 0.134125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The KS value is 5.9 at 6th decile, and the probability threshold is 0.134125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = result_test.predictions.select('LATE', 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|LATE|         probability|\n",
      "+----+--------------------+\n",
      "|   0|[0.89757829248968...|\n",
      "|   0|[0.89906681399244...|\n",
      "|   0|[0.88438826919996...|\n",
      "|   0|[0.89869190762930...|\n",
      "|   0|[0.88346659016632...|\n",
      "|   0|[0.88346659016632...|\n",
      "|   0|[0.89683463410314...|\n",
      "|   0|[0.89683463410314...|\n",
      "|   0|[0.90986401639170...|\n",
      "|   0|[0.90986401639170...|\n",
      "|   0|[0.88841225186886...|\n",
      "|   0|[0.89458204637549...|\n",
      "|   0|[0.89639637890635...|\n",
      "|   0|[0.88879267076089...|\n",
      "|   0|[0.88784235961363...|\n",
      "|   0|[0.88784235961363...|\n",
      "|   0|[0.88784235961363...|\n",
      "|   0|[0.88784235961363...|\n",
      "|   0|[0.88784235961363...|\n",
      "|   0|[0.88784235961363...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.134125"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all thresholds to check the metrics for\n",
    "result_list_new = []\n",
    "threshold_list = [prob_thresh]\n",
    "\n",
    "# Need to add a task column, by comparing the probabilities with threshold\n",
    "for i in threshold_list:\n",
    "    pred = threshold.withColumn('label_p',when(element_extrac(threshold[\"probability\"]) >= i, 1).otherwise(0))\n",
    "    TP = pred.filter(\"LATE==1 AND label_p==1\").count()\n",
    "    FP = pred.filter(\"LATE==0 AND label_p==1\").count()\n",
    "    FN = pred.filter(\"LATE==1 AND label_p==0\").count()\n",
    "    TN = pred.filter(\"LATE==0 AND label_p==0\").count()    \n",
    "    recall = (TP/(TP+FN))\n",
    "    precision = ((TP/(TP+FP)))\n",
    "    x = []\n",
    "    x.append(i)\n",
    "    x.append(precision)\n",
    "    x.append(recall)\n",
    "    x.append(TP)\n",
    "    x.append(TN)\n",
    "    x.append(FP)\n",
    "    x.append(FN)\n",
    "    result_list_new.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.134125, 0.15389861332120935, 0.6503362151777138, 677, 2569, 3722, 364]]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24889705882352942"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
